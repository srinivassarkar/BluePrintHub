{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53dfd99",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# {{ name }} - Data Science Project\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates a typical data science workflow including:\\n\",\n",
    "    \"1. Loading and exploring a dataset\\n\",\n",
    "    \"2. Data preprocessing and cleaning\\n\",\n",
    "    \"3. Exploratory data analysis with visualizations\\n\",\n",
    "    \"4. Building a simple ML model\\n\",\n",
    "    \"5. Evaluating model performance\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Setup and Import Libraries\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Import standard data science libraries\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"{% if 'matplotlib' in libraries %}\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8-whitegrid')\\n\",\n",
    "    \"plt.rcParams['figure.figsize'] = (12, 8)\\n\",\n",
    "    \"{% endif %}\\n\",\n",
    "    \"{% if 'scikit-learn' in libraries %}\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler\\n\",\n",
    "    \"from sklearn.linear_model import LogisticRegression\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestClassifier\\n\",\n",
    "    \"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\\n\",\n",
    "    \"{% endif %}\\n\",\n",
    "    \"{% if 'plotly' in libraries %}\\n\",\n",
    "    \"import plotly.express as px\\n\",\n",
    "    \"import plotly.graph_objects as go\\n\",\n",
    "    \"{% endif %}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set random seed for reproducibility\\n\",\n",
    "    \"np.random.seed(42)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Load and Explore Dataset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load sample dataset (using Iris dataset for this template)\\n\",\n",
    "    \"{% if 'scikit-learn' in libraries %}\\n\",\n",
    "    \"from sklearn.datasets import load_iris\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load the iris dataset\\n\",\n",
    "    \"iris = load_iris()\\n\",\n",
    "    \"data = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\\n\",\n",
    "    \"                    columns=iris['feature_names'] + ['target'])\\n\",\n",
    "    \"{% else %}\\n\",\n",
    "    \"# URL for Iris dataset\\n\",\n",
    "    \"url = \\\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\\\"\\n\",\n",
    "    \"column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\\n\",\n",
    "    \"data = pd.read_csv(url, names=column_names)\\n\",\n",
    "    \"{% endif %}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display basic information about the dataset\\n\",\n",
    "    \"print(\\\"Dataset Shape:\\\", data.shape)\\n\",\n",
    "    \"print(\\\"\\\\nFirst 5 rows:\\\")\\n\",\n",
    "    \"data.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Check for missing values\\n\",\n",
    "    \"print(\\\"Missing values in each column:\\\\n\\\", data.isnull().sum())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Statistical summary\\n\",\n",
    "    \"print(\\\"\\\\nStatistical Summary:\\\")\\n\",\n",
    "    \"data.describe()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Data Preprocessing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Handle missing values if any exist\\n\",\n",
    "    \"# (In this example dataset, there shouldn't be any missing values)\\n\",\n",
    "    \"data_clean = data.copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Feature engineering (if needed)\\n\",\n",
    "    \"# For example, we could create a new feature that's the ratio of sepal length to width\\n\",\n",
    "    \"{% if 'scikit-learn' in libraries %}\\n\",\n",
    "    \"data_clean['sepal_ratio'] = data_clean['sepal length (cm)'] / data_clean['sepal width (cm)']\\n\",\n",
    "    \"data_clean['petal_ratio'] = data_clean['petal length (cm)'] / data_clean['petal width (cm)']\\n\",\n",
    "    \"{% else %}\\n\",\n",
    "    \"data_clean['sepal_ratio'] = data_clean['sepal_length'] / data_clean['sepal_width']\\n\",\n",
    "    \"data_clean['petal_ratio'] = data_clean['petal_length'] / data_clean['petal_width']\\n\",\n",
    "    \"{% endif %}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display the updated dataframe\\n\",\n",
    "    \"data_clean.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Exploratory Data Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"{% if 'matplotlib' in libraries %}\\n\",\n",
    "    \"# Histograms for each feature\\n\",\n",
    "    \"data_clean.hist(figsize=(15, 10))\\n\",\n",
    "    \"plt.suptitle('Feature Distributions', y=1.02, fontsize=16)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"{% endif %}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"{% if 'matplotlib' in libraries %}\\n\",\n",
    "    \"# Correlation matrix and heatmap\\n\",\n",
    "    \"numeric_columns = data_clean.select_dtypes(include=[np.number]).columns\\n\",\n",
    "    \"correlation_matrix = data_clean[numeric_columns].corr()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(12, 10))\\n\",\n",
    "    \"sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\\n\",\n",
    "    \"plt.title('Correlation Matrix', fontsize=16)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"{% endif %}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"{% if 'matplotlib' in libraries %}\\n\",\n",
    "    \"# Pairplot to visualize relationships between features\\n\",\n",
    "    \"{% if 'scikit-learn' in libraries %}\\n\",\n",
    "    \"# Add class names for better visualization\\n\",\n",
    "    \"target_names = iris['target_names']\\n\",\n",
    "    \"data_clean['species'] = data_clean['target'].map({0: target_names[0], 1: target_names[1], 2: target_names[2]})\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Select only the original features and the species for the pairplot\\n\",\n",
    "    \"plot_data = data_clean[iris['feature_names'] + ['species']]\\n\",\n",
    "    \"sns.pairplot(plot_data, hue='species', height=2.5)\\n\",\n",
    "    \"plt.suptitle('Pairwise Feature Relationships by Species', y=1.02, fontsize=16)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"{% else %}\\n\",\n",
    "    \"sns.pairplot(data_clean, hue='class', height=2.5)\\n\",\n",
    "    \"plt.suptitle('Pairwise Feature Relationships by Class', y=1.02, fontsize=16)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"{% endif %}\\n\",\n",
    "    \"{% endif %}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"{% if 'plotly' in libraries %}\\n\",\n",
    "    \"# Interactive scatter plot using Plotly\\n\",\n",
    "    \"{% if 'scikit-learn' in libraries %}\\n\",\n",
    "    \"fig = px.scatter_3d(data_clean, \\n\",\n",
    "    \"                    x='sepal length (cm)', \\n\",\n",
    "    \"                    y='sepal width (cm)', \\n\",\n",
    "    \"                    z='petal length (cm)',\\n\",\n",
    "    \"                    color='species',\\n\",\n",
    "    \"                    symbol='species',\\n\",\n",
    "    \"                    title='3D Scatter Plot of Iris Features')\\n\",\n",
    "    \"{% else %}\\n\",\n",
    "    \"fig = px.scatter_3d(data_clean, \\n\",\n",
    "    \"                    x='sepal_length', \\n\",\n",
    "    \"                    y='sepal_width', \\n\",\n",
    "    \"                    z='petal_length',\\n\",\n",
    "    \"                    color='class',\\n\",\n",
    "    \"                    symbol='class',\\n\",\n",
    "    \"                    title='3D Scatter Plot of Iris Features')\\n\",\n",
    "    \"{% endif %}\\n\",\n",
    "    \"fig.update_layout(scene=dict(xaxis_title='Sepal Length',\\n\",\n",
    "    \"                            yaxis_title='Sepal Width',\\n\",\n",
    "    \"                            zaxis_title='Petal Length'))\\n\",\n",
    "    \"fig.show()\\n\",\n",
    "    \"{% endif %}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Model Building and Evaluation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"{% if 'scikit-learn' in libraries %}\\n\",\n",
    "    \"# Prepare data for modeling\\n\",\n",
    "    \"X = data_clean[iris['feature_names']].values\\n\",\n",
    "    \"y = data_clean['target'].values\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Split data into training and test sets\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Standardize features\\n\",\n",
    "    \"scaler = StandardScaler()\\n\",\n",
    "    \"X_train_scaled = scaler.fit_transform(X_train)\\n\",\n",
    "    \"X_test_scaled = scaler.transform(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Training set shape: {X_train.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Test set shape: {X_test.shape}\\\")\\n\",\n",
    "    \"{% endif %}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"{% if 'scikit-learn' in libraries %}\\n\",\n",
    "    \"# Train a logistic regression model\\n\",\n",
    "    \"lr_model = LogisticRegression(max_iter=200, random_state=42)\\n\",\n",
    "    \"lr_model.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Predictions\\n\",\n",
    "    \"y_pred_lr = lr_model.predict(X_test_scaled)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Evaluate the model\\n\",\n",
    "    \"print(\\\"Logistic Regression Model:\\\")\\n\",\n",
    "    \"print(f\\\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\\\")\\n\",\n",
    "    \"print(\\\"\\\\nClassification Report:\\\")\\n\",\n",
    "    \"print(classification_report(y_test, y_pred_lr, target_names=iris['target_names']))\\n\",\n",
    "    \"{% endif %}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"{% if 'scikit-learn' in libraries %}\\n\",\n",
    "    \"# Train a random forest model\\n\",\n",
    "    \"rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\\n\",\n",
    "    \"rf_model.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Predictions\\n\",\n",
    "    \"y_pred_rf = rf_model.predict(X_test_scaled)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Evaluate the model\\n\",\n",
    "    \"print(\\\"Random Forest Model:\\\")\\n\",\n",
    "    \"print(f\\\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\\\")\\n\",\n",
    "    \"print(\\\"\\\\nClassification Report:\\\")\\n\",\n",
    "    \"print(classification_report(y_test, y_pred_rf, target_names=iris['target_names']))\\n\",\n",
    "    \"{% endif %}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"{% if 'scikit-learn' in libraries and 'matplotlib' in libraries %}\\n\",\n",
    "    \"# Visualize confusion matrix\\n\",\n",
    "    \"plt.figure(figsize=(12, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"cm_lr = confusion_matrix(y_test, y_pred_lr)\\n\",\n",
    "    \"sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', \\n\",\n",
    "    \"            xticklabels=iris['target_names'], \\n\",\n",
    "    \"            yticklabels=iris['target_names'])\\n\",\n",
    "    \"plt.title('Logistic Regression Confusion Matrix')\\n\",\n",
    "    \"plt.ylabel('True Label')\\n\",\n",
    "    \"plt.xlabel('Predicted Label')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"cm_rf = confusion_matrix(y_test, y_pred_rf)\\n\",\n",
    "    \"sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', \\n\",\n",
    "    \"            xticklabels=iris['target_names'], \\n\",\n",
    "    \"            yticklabels=iris['target_names'])\\n\",\n",
    "    \"plt.title('Random Forest Confusion Matrix')\\n\",\n",
    "    \"plt.ylabel('True Label')\\n\",\n",
    "    \"plt.xlabel('Predicted Label')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"{% endif %}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"{% if 'scikit-learn' in libraries and 'matplotlib' in libraries %}\\n\",\n",
    "    \"# Feature importance from Random Forest\\n\",\n",
    "    \"feature_importance = rf_model.feature_importances_\\n\",\n",
    "    \"feature_names = iris['feature_names']\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create a DataFrame for better visualization\\n\",\n",
    "    \"importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\\n\",\n",
    "    \"importance_df = importance_df.sort_values('Importance', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')\\n\",\n",
    "    \"plt.title('Feature Importance from Random Forest', fontsize=16)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"{% endif %}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Conclusions\\n\",\n",
    "    \"\\n\",\n",
    "    \"In this notebook, we've accomplished the following:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Loaded and explored the Iris dataset\\n\",\n",
    "    \"2. Performed basic data preprocessing and feature engineering\\n\",\n",
    "    \"3. Conducted exploratory data analysis with various visualizations\\n\",\n",
    "    \"4. Built and evaluated classification models\\n\",\n",
    "    \"5. Analyzed feature importance to understand what drives predictions\\n\",\n",
    "    \"\\n\",\n",
    "    \"Key findings:\\n\",\n",
    "    \"- The Iris dataset has three distinct species classes that can be relatively well separated using the provided features\\n\",\n",
    "    \"- Petal dimensions appear to be more important for classification than sepal dimensions\\n\",\n",
    "    \"- Random Forest slightly outperformed Logistic Regression in our evaluation\\n\",\n",
    "    \"\\n\",\n",
    "    \"Next steps could include:\\n\",\n",
    "    \"- Hyperparameter tuning to optimize model performance\\n\",\n",
    "    \"- Trying additional classification algorithms\\n\",\n",
    "    \"- Investigating more advanced feature engineering techniques\\n\",\n",
    "    \"- Deploying the model to a production environment\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.13\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
